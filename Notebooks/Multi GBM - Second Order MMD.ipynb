{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5e79ae",
   "metadata": {},
   "source": [
    "# Second-Order Maximum Mean Discrepancy of Multi-Dimensional Geometric Brownian Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1080b",
   "metadata": {},
   "source": [
    "## Change working directory to navigate out of folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38ffc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "path_parent = os.path.dirname(os.getcwd())\n",
    "os.chdir(path_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c748bf5",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7baf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.cuda\n",
    "\n",
    "from MMD.mmd import RBFKernel, SigKernel\n",
    "\n",
    "from GenerateMMDDataset.mmd_dataset_base import save_dataset, load_dataset, save_path_params, load_path_params\n",
    "from GenerateMMDDataset.multi_gbm_dataset import GenerateMultiDimensionalGBM\n",
    "\n",
    "from StochasticModels.geometric_brownian_motion import BlackScholesExactSimulationSobolNDim\n",
    "\n",
    "from RegressionModel.pricing_model import PricingModel\n",
    "from RegressionModel.mmd_model import SecondOrderMMDApprox\n",
    "from RegressionModel.regression_model import RegressionModel, RegressionNeuralNetwork, DatasetDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee08d1",
   "metadata": {},
   "source": [
    "## Set PyTorch Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e967d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939bd48",
   "metadata": {},
   "source": [
    "## Neural Network Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ca40b",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genMultiGBMData = GenerateMultiDimensionalGBM(20, device, 50, 0, 3, 0.5)\n",
    "multi_gbm_mmd_dataset, multi_gbm_path_dataset, multi_gbm_sample_path_param_dict = genMultiGBMData.generate_mmd_dataset(1000, 24, 200, (1, 1), (0.2, 0.8), estimator='ub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(multi_gbm_mmd_dataset, 'Multi GBM/Data/multi_gbm_mmd_dataset_1000_second_order_samples_ub.pt')\n",
    "\n",
    "save_path_params(multi_gbm_sample_path_param_dict, \n",
    "                 'Multi GBM/Data/multi_gbm_sample_path_param_dict_1000_second_order_samples_ub.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269850fb",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f49dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gbm_mmd_dataset = torch.load('Multi GBM/Data/multi_gbm_mmd_dataset_1000_second_order_samples_ub.pt')\n",
    "\n",
    "multi_gbm_sample_path_param_dict = load_path_params('Multi GBM/Data/multi_gbm_sample_path_param_dict_1000_second_order_samples_ub.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fb0d6",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8785d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_multi_gbm = multi_gbm_sample_path_param_dict['M']\n",
    "N_multi_gbm = multi_gbm_sample_path_param_dict['N']\n",
    "dim = multi_gbm_sample_path_param_dict['Dim']\n",
    "\n",
    "\n",
    "multi_gbm_mmd_features = []\n",
    "multi_gbm_mmd_labels = []\n",
    "for i in range(M_multi_gbm):\n",
    "    for j in range(N_multi_gbm): \n",
    "        new_feature = [multi_gbm_sample_path_param_dict['Sigma'][i][int(k/2)] if k%2 == 0 else multi_gbm_sample_path_param_dict['Sigma'][j][int(k/2)] for k in range(2*dim)]\n",
    "        new_feature += [multi_gbm_sample_path_param_dict['Correlation'][i], multi_gbm_sample_path_param_dict['Correlation'][j]]\n",
    "        multi_gbm_mmd_features.append(new_feature)\n",
    "        multi_gbm_mmd_labels.append(multi_gbm_mmd_dataset[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gbm_mmd_training_param_dict = {\n",
    "    'lr' : 3e-3,\n",
    "    'Epochs' : 200,\n",
    "    'l2_weight' : 0.0,\n",
    "    'l1_weight' : 0.0,\n",
    "    'Train/Val Split' : 0.8\n",
    "}\n",
    "\n",
    "\n",
    "multi_gbm_mmd_dataset_loader_params = {\n",
    "    'batch_size' : 256,\n",
    "    'shuffle' : True,\n",
    "    'num_workers' : 0\n",
    "}\n",
    "\n",
    "multi_gbm_mmd_input_dimension = 8\n",
    "\n",
    "multi_gbm_mmd_model_param_dict = {\n",
    "    'input_dimension' : multi_gbm_mmd_input_dimension,\n",
    "    'intermediate_dimensions' : [30, 30, 30, 30],\n",
    "    'activation_functions' : [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU()],\n",
    "    'add_layer_norm' : [False, False, False, False], \n",
    "    'output_dimension' : 1,\n",
    "    'output_activation_fn' : None\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    multi_gbm_second_order_mmd_model = SecondOrderMMDApprox(multi_gbm_mmd_model_param_dict, \n",
    "                                                        multi_gbm_mmd_training_param_dict,\n",
    "                                                        multi_gbm_mmd_dataset_loader_params, nn.MSELoss(), device,\n",
    "                                                        f'Multi GBM/MMD Model/multi_gbm_mmd_scaler_{i+1}.pkl')\n",
    "    \n",
    "    multi_gbm_second_order_mmd_model.fit(torch.tensor(multi_gbm_mmd_features).float(),\n",
    "                                     torch.tensor(multi_gbm_mmd_labels).float(),\n",
    "                                     **{'filename' : f'Multi GBM/MMD Model/multi_gbm_mmd_checkpoint_{i+1}.pth.tar',\n",
    "                                        'best_model_filename' : f'Multi GBM/MMD Model/multi_gbm_mmd_model_best_{i+1}.pth.tar'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b8a381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.877856791717932e-05\n",
      "4.9644229827584214e-06\n",
      "0.00010450972513353918\n",
      "1.4837267565938272e-06\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "for i in range(5):\n",
    "    \n",
    "    checkpoint = torch.load(f'Multi GBM/MMD Model/multi_gbm_mmd_model_best_{i+1}.pth.tar', map_location='cpu')\n",
    "    train_losses.append(checkpoint['train_loss'])\n",
    "    valid_losses.append(checkpoint['valid_loss'])\n",
    "    \n",
    "print(np.mean(train_losses))\n",
    "print(np.std(train_losses))\n",
    "\n",
    "print(np.mean(valid_losses))\n",
    "print(np.std(valid_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fa858",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2faec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Initial Distances\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0fcf485294575aeee34e07049276d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Computing Initial Distances\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Computing Next Batch of Distances\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a72029821284f57a4b0a69e21f778ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Computing All Distances\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genMultiGBMData = GenerateMultiDimensionalGBM(20, device, 50, 0, 3, 0.5)\n",
    "multi_gbm_mmd_dataset, multi_gbm_path_dataset, multi_gbm_sample_path_param_dict = genMultiGBMData.generate_mmd_dataset(40, 24, 200, (1, 1), (0.2, 0.8), estimator='ub')\n",
    "\n",
    "\n",
    "M_multi_gbm = multi_gbm_sample_path_param_dict['M']\n",
    "N_multi_gbm = multi_gbm_sample_path_param_dict['N']\n",
    "dim = multi_gbm_sample_path_param_dict['Dim']\n",
    "multi_gbm_mmd_features = []\n",
    "multi_gbm_mmd_labels = []\n",
    "for i in range(M_multi_gbm):\n",
    "    for j in range(N_multi_gbm): \n",
    "        new_feature = [multi_gbm_sample_path_param_dict['Sigma'][i][int(k/2)] if k%2 == 0 else multi_gbm_sample_path_param_dict['Sigma'][j][int(k/2)] for k in range(2*dim)]\n",
    "        new_feature += [multi_gbm_sample_path_param_dict['Correlation'][i], multi_gbm_sample_path_param_dict['Correlation'][j]]\n",
    "        multi_gbm_mmd_features.append(new_feature)\n",
    "        multi_gbm_mmd_labels.append(multi_gbm_mmd_dataset[i][j].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7035dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00219359314125947\n",
      "0.00014377245652035786\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    multi_gbm_second_order_mmd_model = SecondOrderMMDApprox(multi_gbm_mmd_model_param_dict, \n",
    "                                                        multi_gbm_mmd_training_param_dict,\n",
    "                                                        multi_gbm_mmd_dataset_loader_params, nn.MSELoss(), device,\n",
    "                                                        f'Multi GBM/MMD Model/multi_gbm_mmd_scaler_{i+1}.pkl')\n",
    "    \n",
    "    multi_gbm_second_order_mmd_model.load_best_model(f'Multi GBM/MMD Model/multi_gbm_mmd_model_best_{i+1}.pth.tar', \n",
    "                                                     f'Multi GBM/MMD Model/multi_gbm_mmd_scaler_{i+1}.pkl')\n",
    "    \n",
    "    multi_gbm_second_order_mmd_model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        distances = multi_gbm_second_order_mmd_model.transform(torch.tensor(multi_gbm_mmd_features))\n",
    "        test_losses.append(mean_squared_error(distances.cpu(), multi_gbm_mmd_labels))\n",
    "        \n",
    "print(np.mean(test_losses))\n",
    "print(np.std(test_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338324df",
   "metadata": {},
   "source": [
    "### Test to Determine whether $\\mathcal{NN}_{2}^{\\text{MGBM}} \\left( \\cdot, \\cdot \\right)$ is a Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca054d00",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb4f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gbm_mmd_input_dimension = 8\n",
    "\n",
    "multi_gbm_mmd_model_param_dict = {\n",
    "    'input_dimension' : multi_gbm_mmd_input_dimension,\n",
    "    'intermediate_dimensions' : [30, 30, 30, 30],\n",
    "    'activation_functions' : [nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU()], \n",
    "    'add_layer_norm' : [False, False, False, False], \n",
    "    'output_dimension' : 1,\n",
    "    'output_activation_fn' : None\n",
    "}\n",
    "\n",
    "multi_gbm_second_order_mmd_model = SecondOrderMMDApprox(multi_gbm_mmd_model_param_dict, \n",
    "                                                        None,\n",
    "                                                        None, None, device,\n",
    "                                                        'Multi GBM/MMD Model/multi_gbm_mmd_scaler_1.pkl')\n",
    "\n",
    "multi_gbm_second_order_mmd_model.load_best_model('Multi GBM/MMD Model/multi_gbm_mmd_model_best_1.pth.tar', \n",
    "                                                 'Multi GBM/MMD Model/multi_gbm_mmd_scaler_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47494454",
   "metadata": {},
   "source": [
    "- #### Identity of Indiscernables: $\\sqrt{\\mathcal{NN}_{2}^{\\text{MGBM}} \\left(\\Theta, \\Theta \\right)} = 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "854bb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 50000\n",
      "Threshold: 0.05\n",
      "Number of Distances Below Threshold: 49336\n"
     ]
    }
   ],
   "source": [
    "mmd_values = []\n",
    "cond_sat = []\n",
    "num_sim = 50000\n",
    "threshold = 0.05\n",
    "\n",
    "multi_gbm_second_order_mmd_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(num_sim):\n",
    "        sigma_1 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_2 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_3 = np.random.uniform(0.2, 0.8)\n",
    "        corr = np.random.uniform(0.05, 0.95)\n",
    "\n",
    "        distance = torch.maximum(\n",
    "            multi_gbm_second_order_mmd_model.transform(torch.tensor(\n",
    "                [sigma_1, sigma_1, sigma_2, sigma_2, sigma_3, sigma_3, corr, corr]\n",
    "            ).unsqueeze(0).float()).squeeze(0).squeeze(0), torch.tensor(0.0)).cpu()\n",
    "        \n",
    "        mmd_values.append(distance)\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cond_sat.append(True)\n",
    "        else:\n",
    "            cond_sat.append(False)\n",
    "            \n",
    "counter_dict = Counter(cond_sat)\n",
    "print(f'Number of Samples: {num_sim}')\n",
    "print(f'Threshold: {threshold}')\n",
    "print(f'Number of Distances Below Threshold: {counter_dict[True]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0b6bc",
   "metadata": {},
   "source": [
    "- #### Symmetry: $\\sqrt{\\mathcal{NN}_{2}^{\\text{MGBM}} \\left(\\Theta_{1}, \\Theta_{2} \\right)} = \\sqrt{\\mathcal{NN}_{2}^{\\text{MGBM}} \\left(\\Theta_{2}, \\Theta_{1} \\right)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f724f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 50000\n",
      "Threshold: 0.05\n",
      "Number of Distances Below Threshold: 38741\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.05\n",
    "num_sim = 50000\n",
    "\n",
    "is_sat = []\n",
    "\n",
    "multi_gbm_second_order_mmd_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(num_sim):\n",
    "        \n",
    "        sigma_1_1 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_2_1 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_3_1 = np.random.uniform(0.2, 0.8)\n",
    "        corr_1 = np.random.uniform(0.05, 0.95)\n",
    "        \n",
    "        sigma_1_2 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_2_2 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_3_2 = np.random.uniform(0.2, 0.8)\n",
    "        corr_2 = np.random.uniform(0.05, 0.95)\n",
    "\n",
    "        d1 = torch.maximum(\n",
    "            multi_gbm_second_order_mmd_model.transform(torch.tensor(\n",
    "                [sigma_1_1, sigma_1_2, sigma_2_1, sigma_2_2, sigma_3_1, sigma_3_2, corr_1, corr_2]\n",
    "            ).unsqueeze(0).float()).squeeze(0).squeeze(0), torch.tensor(0.0)).cpu()\n",
    "        \n",
    "        d2 = torch.maximum(\n",
    "            multi_gbm_second_order_mmd_model.transform(torch.tensor(\n",
    "                [sigma_1_2, sigma_1_1, sigma_2_2, sigma_2_1, sigma_3_2, sigma_3_1, corr_2, corr_1]\n",
    "            ).unsqueeze(0).float()).squeeze(0).squeeze(0), torch.tensor(0.0)).cpu()\n",
    "                \n",
    "        if abs(np.sqrt(d1)-np.sqrt(d2)) < threshold:\n",
    "            is_sat.append(True)\n",
    "        else:\n",
    "            is_sat.append(False)\n",
    "\n",
    "symm_counter_dict = Counter(is_sat)\n",
    "print(f'Number of Samples: {num_sim}')\n",
    "print(f'Threshold: {threshold}')\n",
    "print(f'Number of Distances Below Threshold: {symm_counter_dict[True]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afee941",
   "metadata": {},
   "source": [
    "- #### Triangle Inequality: $\\sqrt{\\mathcal{NN}_{\\mathcal{D}^{2}}^{\\text{MGBM}} \\left(\\Theta_{1}, \\Theta_{3} \\right)} \\leq \\sqrt{\\mathcal{NN}_{\\mathcal{D}^{2}}^{\\text{MGBM}} \\left(\\Theta_{1}, \\Theta_{2} \\right)} + \\sqrt{\\mathcal{NN}_{\\mathcal{D}^{2}}^{\\text{MGBM}} \\left(\\Theta_{2}, \\Theta_{3} \\right)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97dc8fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 50000\n",
      "Number of Samples Satisfying the Triangle Inequality: 49937\n"
     ]
    }
   ],
   "source": [
    "triag_inq_sat = []\n",
    "num_sim = 50000\n",
    "\n",
    "multi_gbm_second_order_mmd_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(num_sim):\n",
    "        \n",
    "        sigma_1_1 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_2_1 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_3_1 = np.random.uniform(0.2, 0.8)\n",
    "        corr_1 = np.random.uniform(0.05, 0.95)\n",
    "        \n",
    "        sigma_1_2 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_2_2 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_3_2 = np.random.uniform(0.2, 0.8)\n",
    "        corr_2 = np.random.uniform(0.05, 0.95)\n",
    "        \n",
    "        sigma_1_3 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_2_3 = np.random.uniform(0.2, 0.8)\n",
    "        sigma_3_3 = np.random.uniform(0.2, 0.8)\n",
    "        corr_3 = np.random.uniform(0.05, 0.95)\n",
    "\n",
    "        d1 = torch.maximum(\n",
    "            multi_gbm_second_order_mmd_model.transform(torch.tensor(\n",
    "                [sigma_1_1, sigma_1_3, sigma_2_1, sigma_2_3, sigma_3_1, sigma_3_3, corr_1, corr_3]\n",
    "            ).unsqueeze(0).float()).squeeze(0).squeeze(0), torch.tensor(0.0)).cpu()\n",
    "        \n",
    "        d2 = torch.maximum(\n",
    "            multi_gbm_second_order_mmd_model.transform(torch.tensor(\n",
    "                [sigma_1_1, sigma_1_2, sigma_2_1, sigma_2_2, sigma_3_1, sigma_3_2, corr_1, corr_2]\n",
    "            ).unsqueeze(0).float()).squeeze(0).squeeze(0), torch.tensor(0.0)).cpu()\n",
    "        \n",
    "        d3 = torch.maximum(\n",
    "            multi_gbm_second_order_mmd_model.transform(torch.tensor(\n",
    "                [sigma_1_2, sigma_1_3, sigma_2_2, sigma_2_3, sigma_3_2, sigma_3_3, corr_2, corr_3]\n",
    "            ).unsqueeze(0).float()).squeeze(0).squeeze(0), torch.tensor(0.0)).cpu()\n",
    "        \n",
    "        if np.sqrt(d1) <= (np.sqrt(d2)+np.sqrt(d3)):\n",
    "            triag_inq_sat.append(True)\n",
    "        else:\n",
    "            triag_inq_sat.append(False)\n",
    "            \n",
    "triag_inq_counter_dict = Counter(triag_inq_sat)\n",
    "print(f'Number of Samples: {num_sim}')\n",
    "print(f'Number of Samples Satisfying the Triangle Inequality: {triag_inq_counter_dict[True]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd38400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
